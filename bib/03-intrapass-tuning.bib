@inproceedings{cummins2017end,
  title={End-to-end deep learning of optimization heuristics},
  author={Cummins, Chris and Petoumenos, Pavlos and Wang, Zheng and Leather, Hugh},
  booktitle={2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)},
  pages={219--232},
  year={2017},
  organization={IEEE},
  abstract = {Accurate automatic optimization heuristics are necessary for dealing with thecomplexity and diversity of modern hardware and software. Machine learning is aproven technique for learning such heuristics, but its success is bound by thequality of the features used. These features must be hand crafted by developersthrough a combination of expert domain knowledge and trial and error. This makesthe quality of the final model directly dependent on the skill and availabletime of the system architect. Our work introduces a better way for building heuristics. We develop a deepneural network that learns heuristics over raw code, entirely without using codefeatures. The neural network simultaneously constructs appropriaterepresentations of the code and learns how best to optimize, removing the needfor manual feature creation. Further, we show that our neural nets can transferlearning from one optimization problem to another, improving the accuracy of newmodels, without the help of human experts. We compare the effectiveness of our automatically generated heuristics againstones with features hand-picked by experts. We examine two challenging tasks:predicting optimal mapping for heterogeneous parallelism and GPU threadcoarsening factors. In 89% of the cases, the quality of our fully automaticheuristics matches or surpasses that of state-of-the-art predictive models usinghand-crafted features, providing on average 14% and 12% more performance withno human effort expended on designing features.},
  keywords = {herustic learning},
  link = {10.1109/PACT.2017.24},
}

@inproceedings{cummins2021programl,
  title={Programl: A graph-based program representation for data flow analysis and compiler optimizations},
  author={Cummins, Chris and Fisches, Zacharias V and Ben-Nun, Tal and Hoefler, Torsten and Oâ€™Boyle, Michael FP and Leather, Hugh},
  booktitle={International Conference on Machine Learning},
  pages={2244--2253},
  year={2021},
  organization={PMLR},
  abstract = {Machine learning (ML) is increasingly seen as a viable approach for building compiler optimization heuristics, but many ML methods cannot replicate even the simplest of the data flow analyses that are critical to making good optimization decisions. We posit that if ML cannot do that, then it is insufficiently able to reason about programs. We formulate data flow analyses as supervised learning tasks and introduce a large open dataset of programs and their corresponding labels from several analyses. We use this dataset to benchmark ML methods and show that they struggle on these fundamental program reasoning tasks. We propose ProGraML - Program Graphs for Machine Learning - a language-independent, portable representation of program semantics. ProGraML overcomes the limitations of prior works and yields improved performance on downstream optimization tasks.},
  link = {https://proceedings.mlr.press/v139/cummins21a.html},
  keywords = {loop,dfg,SVM},
}